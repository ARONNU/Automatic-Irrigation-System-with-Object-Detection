import cv2
import numpy as np
import tensorflow as tf

# Load the TensorFlow model
model = tf.saved_model.load('path/to/model.pb')

# Capture video from the camera
cap = cv2.VideoCapture(0)

# Define a dictionary to map class IDs to class names
class_map = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'bus', 5: 'truck', 6: 'traffic light', 7: 'stop sign', 8: 'fire hydrant', 9: 'bench'}

while True:
    # Capture the next frame
    ret, frame = cap.read()

    # Preprocess the frame
    frame = cv2.resize(frame, (300, 300))
    frame = np.expand_dims(frame, axis=0)
    frame = frame.astype('float32') / 255.0

    # Perform object detection
    detections = model(frame)

    # Extract detection results
    boxes = detections['detection_boxes']
    classes = detections['detection_classes']
    scores = detections['detection_scores']

    # Apply non-maximum suppression
    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes=10, iou_threshold=0.5)

    # Visualize the detection results
    for i in nms_indices:
        box = boxes[i].numpy()
        class_id = classes[i].numpy()
        score = scores[i].numpy()

        label = '%s: %.2f' % (class_map[class_id], score)
        x1, y1, x2, y2 = box * frame.shape[1:3]

        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
        cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Display the visualized frame
    cv2.imshow('Detection Results', frame)

    # Check if the user wants to quit
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the camera and destroy all windows
cap.release()
cv2.destroyAllWindows()
